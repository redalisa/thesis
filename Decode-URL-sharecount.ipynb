{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df2c56-e315-4cd5-b65e-c0104463bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import lxml.etree\n",
    "\n",
    "#pip install geopandas\n",
    "#pip install spacy\n",
    "#python -m spacy download en_core_web_sm\n",
    "#pip install lxml\n",
    "#pip install parser-libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcdaa7-2fc2-446e-9ee7-0cdcefa1e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset \n",
    "df = pd.read_json('animal_news_database.json', lines = True)\n",
    "# Read in the datasets defining our subset data\n",
    "\n",
    "#undoc = pd.read_csv(\"undoc_species.csv\", sep = \";\")\n",
    "charismatic = pd.read_csv(\"charismatic_16.csv\", sep = \";\")\n",
    "#edge = pd.read_csv(\"non_charismatic_20.csv\", sep = \";\")\n",
    "charismatic = charismatic.rename(columns = {'Scientifc Name' : 'scientific_name'})\n",
    "\n",
    "\n",
    "# Drop Twitter handles as they are not species names\n",
    "df = df[df.scientific_name.str.contains('@') == False]\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "# How many species listed total in this dataset\n",
    "#df['scientific_name'].nunique()\n",
    "\n",
    "# Add new column for storing the values article amount found under each species type \n",
    "df['article_amt'] = df['articles'].str.len()\n",
    "\n",
    "\n",
    "# Read in the CITES data to join with the top 10 (or 20) most reported on species \n",
    "cites1 = pd.read_csv(\"cites1.csv\", delimiter = ';')\n",
    "\n",
    "# Keep only most relevant columns\n",
    "cites1 = cites1[['Kingdom', 'Class', 'Order', 'Family', 'Genus', 'Species', 'Scientific Name', 'Listing', 'NativeDistributionFullNames', 'Extinct_Distribution']]\n",
    "\n",
    "cites1 = cites1.rename(columns = {'Scientific Name' : 'scientific_name'})\n",
    "\n",
    "# Do the same for the entire dataframe\n",
    "df = df.merge(cites1, on = 'scientific_name', how = 'inner')\n",
    "\n",
    "\n",
    "df = df.drop(['_id'], axis=1)\n",
    "\n",
    "\n",
    "# Do the same for the entire dataframe\n",
    "rizz = df.merge(charismatic, on = 'scientific_name', how = 'inner')\n",
    "#dg = df.merge(edge, on = 'scientific_name', how = 'inner')\n",
    "\n",
    "# Explode the articles column\n",
    "s = rizz['articles'].map(dict.values).explode()\n",
    "# NaN values need to be droppped\n",
    "s = s.dropna()\n",
    "# Drop the column articles and join the exploded values to the dataframe\n",
    "rizz_articles = rizz.drop(columns=['articles']).join(pd.DataFrame([*s], s.index))\n",
    "\n",
    "\n",
    "# Processing for articles       \n",
    "# keep only unique article instances\n",
    "rizz_media = rizz_articles.drop_duplicates(subset=['text'])\n",
    "\n",
    "# Transform date column into DateTime\n",
    "rizz_media[\"date\"] = pd.to_datetime(rizz_media[\"date\"])\n",
    "# Sort by oldest to newest\n",
    "rizz_media = rizz_media.sort_values(by=\"date\")\n",
    "\n",
    "\n",
    "rizz_media = rizz_media.drop(columns=['Unnamed: 8', 'article_amt'])\n",
    "rizz_media.reset_index(drop = True, inplace = True)\n",
    "rizz_media = rizz_media[rizz_media['text'].notna()]\n",
    "rizz_media\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed45543-fd4a-4bb2-bc48-5290ee782aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_full_url(short_url):\n",
    "        try:\n",
    "            session = requests.Session()  # so connections are recycled\n",
    "            resp = session.head(short_url, allow_redirects=True, timeout=10)\n",
    "            url = resp.url\n",
    "            \n",
    "            if 'url=' in url and '&ct' in url:\n",
    "                return url.split('url=')[1].split('&ct')[0]\n",
    "            else:\n",
    "                return short_url\n",
    "               \n",
    "        except Exception:   \n",
    "            return short_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1f13a-dfdb-4f3c-8242-8b9857569407",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in rizz_media['link']:\n",
    "    url = link\n",
    "    browser = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "    headers = {'User-Agent':browser,}\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    links = soup.findAll(\"a\")\n",
    "    \n",
    "    print(soup)\n",
    "    \n",
    "    \n",
    "    break\n",
    "\n",
    "    l = []\n",
    "\n",
    "    for x in soup.find_all(\"a\",href=re.compile(\"(?<=/url\\?q=)(htt.*://.*)\")):\n",
    "        l.append(re.split(\":(?=http)\",link[\"href\"].replace(\"/url?q=\",\"\"))[0])\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb43a4-6219-4e34-b878-0c481a5df7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in rizz_media['link']:\n",
    "    session = requests.Session()  # so connections are recycled\n",
    "    resp = session.head(link, allow_redirects=True, timeout=10)\n",
    "    url = resp.url\n",
    "    \n",
    "    print(url)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e95ef1-fa64-4596-b341-58f4c3a04993",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decoding the google news article links with base64 so they can be utilized by other APIs\n",
    "\n",
    "rizz_media['url'] = None\n",
    "test = []\n",
    "\n",
    "for link in rizz_media['link']:\n",
    "    coded = link.strip(\"https://news.google.com/articles/\")\n",
    "    \n",
    "    url = base64.b64decode(coded + '==')[4:].decode('utf-8', \"backslashreplace\").split('\\\\')[0]\n",
    "    #dic = {'url': [url]}\n",
    "    #rizz_media.append(pd.DataFrame(dic))\n",
    "    test.append(url)\n",
    "    #test = pd.concat([rizz_media, pd.DataFrame(dic)])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdcb0ce-12f5-4d39-b529-a9f99a852173",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test:\n",
    "    for x in i.values():\n",
    "        for y in x:\n",
    "            print(y)\n",
    "            print(y[y.find(b'https'):])\n",
    "            \n",
    "            \n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d1b8d-b78e-402f-baa5-495c6b09c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rizz_media['url'] = pd.Series(test)\n",
    "rizz_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec335f-953c-4523-81c8-1a52a0207896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.structures import CaseInsensitiveDict\n",
    "\n",
    "sharecount = []\n",
    "for url in test[:20]: \n",
    "    \n",
    "    api = \"https://api.sharedcount.com/v1.1?apikey=2a0336186dc8f5740fef9c1eb81947d66119c29f&url=\" + url\n",
    "    \n",
    "    headers = CaseInsensitiveDict()\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "    \n",
    "    resp = requests.get(api, headers=headers)\n",
    "    details = resp.json()\n",
    "    for n in range(len(details)):\n",
    "        count = details[n]['Facebook']['share_count']\n",
    "        \n",
    "    \n",
    "    #print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b74981-9bd0-4f52-b0f4-20fbaa033f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
