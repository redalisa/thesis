{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20df2c56-e315-4cd5-b65e-c0104463bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "#import lxml.etree\n",
    "\n",
    "#pip install geopandas\n",
    "#pip install spacy\n",
    "#python -m spacy download en_core_web_sm\n",
    "#pip install lxml\n",
    "#pip install parser-libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ad834b-f2bd-436d-8be5-9217ac7ed44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Decode encoded Google News entry URLs.\"\"\"\n",
    "import base64\n",
    "import functools\n",
    "import re\n",
    "\n",
    "# Ref: https://stackoverflow.com/a/59023463/\n",
    "\n",
    "_ENCODED_URL_PREFIX = \"https://news.google.com/articles/\"\n",
    "_ENCODED_URL_RE = re.compile(fr\"^{re.escape(_ENCODED_URL_PREFIX)}(?P<encoded_url>[^?]+)\")\n",
    "_DECODED_URL_RE = re.compile(rb'^\\x08\\x13\".+?(?P<primary_url>http[^\\xd2]+)\\xd2\\x01')\n",
    "\n",
    "\n",
    "@functools.lru_cache(2048)\n",
    "def _decode_google_news_url(url: str) -> str:\n",
    "    match = _ENCODED_URL_RE.match(url)\n",
    "    encoded_text = match.groupdict()[\"encoded_url\"]  # type: ignore\n",
    "    encoded_text += \"===\"  # Fix incorrect padding. Ref: https://stackoverflow.com/a/49459036/\n",
    "    decoded_text = base64.urlsafe_b64decode(encoded_text)\n",
    "\n",
    "    match = _DECODED_URL_RE.match(decoded_text)\n",
    "    primary_url = match.groupdict()[\"primary_url\"]  # type: ignore\n",
    "    primary_url = primary_url.decode()\n",
    "    return primary_url\n",
    "\n",
    "\n",
    "def decode_google_news_url(url: str) -> str:  # Not cached because not all Google News URLs are encoded.\n",
    "    \"\"\"Return Google News entry URLs after decoding their encoding as applicable.\"\"\"\n",
    "    return _decode_google_news_url(url) if url.startswith(_ENCODED_URL_PREFIX) else url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e389f6f-1515-4527-8335-00a684d49363",
   "metadata": {},
   "outputs": [],
   "source": [
    "rz = pd.read_csv(\"full_rizz.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b96ce2-fdce-4b59-8f65-b88fb21e7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "for url in rz['link']:\n",
    "    try:\n",
    "        new = decode_google_news_url(url)\n",
    "        urls.append(new)\n",
    "        \n",
    "    except AttributeError:\n",
    "        rz.drop(rz.loc[rz.link == url].index, inplace = True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ddba0d6-3f88-424d-9e86-54041608b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rz = rz.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cffb7369-a8aa-4473-b862-40376f33c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rz = pd.concat([rz, pd.DataFrame({'url':urls})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec335f-953c-4523-81c8-1a52a0207896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.structures import CaseInsensitiveDict\n",
    "\n",
    "sharecount = []\n",
    "for url in urls[:20]: \n",
    "    \n",
    "    api = \"https://api.sharedcount.com/v1.1?apikey=2a0336186dc8f5740fef9c1eb81947d66119c29f&url=\" + url\n",
    "    \n",
    "    headers = CaseInsensitiveDict()\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "    \n",
    "    resp = requests.get(api, headers=headers)\n",
    "    details = resp.json()\n",
    "    for n in range(len(details)):\n",
    "        count = details[n]['Facebook']['share_count']\n",
    "        \n",
    "    \n",
    "    #print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b74981-9bd0-4f52-b0f4-20fbaa033f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
